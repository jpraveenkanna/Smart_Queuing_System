{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting person_detect.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile person_detect.py\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "class Queue:\n",
    "    '''\n",
    "    Class for dealing with queues\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.queues=[]\n",
    "\n",
    "    def add_queue(self, points):\n",
    "        self.queues.append(points)\n",
    "\n",
    "    def get_queues(self, image):\n",
    "        for q in self.queues:\n",
    "            x_min, y_min, x_max, y_max=q\n",
    "            frame=image[y_min:y_max, x_min:x_max]\n",
    "            yield frame\n",
    "    \n",
    "    def check_coords(self, coords):\n",
    "        d={k+1:0 for k in range(len(self.queues))}\n",
    "        for coord in coords:\n",
    "            for i, q in enumerate(self.queues):\n",
    "                if coord[0]>q[0] and coord[2]<q[2]:\n",
    "                    d[i+1]+=1\n",
    "        return d\n",
    "\n",
    "\n",
    "class PersonDetect:\n",
    "    '''\n",
    "    Class for the Person Detection Model.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model_name, device, threshold=0.60):\n",
    "        self.model_weights=model_name+'.bin'\n",
    "        self.model_structure=model_name+'.xml'\n",
    "        self.device=device\n",
    "        self.threshold=threshold\n",
    "\n",
    "        try:\n",
    "            \n",
    "            self.model=IENetwork(self.model_structure, self.model_weights)\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"Could not Initialise the network. Have you enterred the correct model path?\")\n",
    "           \n",
    "        self.input_name=next(iter(self.model.inputs))\n",
    "        self.input_shape=self.model.inputs[self.input_name].shape\n",
    "        self.output_name=next(iter(self.model.outputs))\n",
    "        self.output_shape=self.model.outputs[self.output_name].shape\n",
    "\n",
    "       \n",
    "        \n",
    "    def load_model(self):\n",
    "        \n",
    "        core = IECore()\n",
    "        self.net = core.load_network(network=self.model, device_name=self.device, num_requests=1)\n",
    "        \n",
    "\n",
    "        \n",
    "    def predict(self, image):\n",
    "        \n",
    "        net_input = self.preprocess_input(image)\n",
    "        start=time.time()\n",
    "        self.res = self.net.infer(net_input)\n",
    "        inference_time=time.time()-start\n",
    "        fps=100/inference_time\n",
    "\n",
    "        output_image,coordinate = self.draw_outputs(image)\n",
    "        \n",
    "        cv2.putText(output_image, f\"Inference time: {round(inference_time,3)}\", (15, 85), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,153,153), 2)\n",
    "        \n",
    "        return output_image,coordinate\n",
    "        \n",
    "        \n",
    "    \n",
    "    def draw_outputs(self,image):\n",
    "        #image = cv2.imread(args.image)  #uncomment for image\n",
    "        data = self.res['detection_out'][0][0]\n",
    "        ih, iw = image.shape[:-1]\n",
    "        tmp_image = image\n",
    "        boxes=[]\n",
    "        probability=[]\n",
    "\n",
    "        for number, infer_results in enumerate(data):\n",
    "            if (np.int(infer_results[1]) == 1 and infer_results[2] > self.threshold):\n",
    "\n",
    "                xmin = np.int(iw * infer_results[3])\n",
    "                ymin = np.int(ih * infer_results[4])\n",
    "                xmax = np.int(iw * infer_results[5])\n",
    "                ymax = np.int(ih * infer_results[6])\n",
    "                boxes.append([xmin, ymin, xmax, ymax])\n",
    "                probability.append([infer_results[2]])\n",
    "\n",
    "        for box,prob in zip(boxes,probability):\n",
    "            \n",
    "            cv2.rectangle(tmp_image, (box[0], box[1]), (box[2], box[3]), (232, 35, 244), 2)\n",
    "            mid_x,mid_y =  (box[2]+(box[0]-box[2])//2),(box[3]+(box[1]-box[3])//2)\n",
    "            \n",
    "\n",
    "        \n",
    "        return tmp_image,boxes\n",
    "\n",
    "\n",
    "\n",
    "    def preprocess_input(self, image):\n",
    "        #image = cv2.imread(args.image) #uncomment for image\n",
    "        n,c,h,w = self.input_shape\n",
    "        images = np.ndarray(shape=(n, c, h, w))\n",
    "        image_shape = (image.shape[1], image.shape[0])\n",
    "        resized_input_image = cv2.resize(image, (w, h))\n",
    "        resized_input_image = resized_input_image.transpose((2, 0, 1))  \n",
    "        images[0] = resized_input_image\n",
    "        net_input = {'data': images[0]}\n",
    "        return net_input\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    #args =arguments()\n",
    "    model=args.model\n",
    "    device=args.device\n",
    "    video_file=args.video\n",
    "    max_people=args.max_people\n",
    "    threshold=args.threshold\n",
    "    output_path=args.output_path\n",
    "    queue_param = args.queue_param\n",
    "\n",
    "\n",
    "    start_model_load_time=time.time()\n",
    "    pd= PersonDetect(model, device, threshold)\n",
    "    pd.load_model()\n",
    "\n",
    "    total_model_load_time = time.time() - start_model_load_time\n",
    "    print(\"Total_model_load_time: \",total_model_load_time)\n",
    "\n",
    "    queue=Queue()\n",
    "\n",
    "\n",
    "    try:\n",
    "        queue_param=np.load(queue_param)\n",
    "        for q in queue_param:\n",
    "            queue.add_queue(q)\n",
    "    except:\n",
    "        print(\"error loading queue param file\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        cap=cv2.VideoCapture(video_file)\n",
    "    except FileNotFoundError:\n",
    "         print(\"Cannot locate video file: \", video_file)\n",
    "    except Exception as e:\n",
    "        print(\"Something else went wrong with the video file: \", e)\n",
    "\n",
    "    initial_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    initial_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    video_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    out_video = cv2.VideoWriter(os.path.join(output_path, 'output_video.mp4'), cv2.VideoWriter_fourcc(*'avc1'), fps, (initial_w, initial_h), True)\n",
    "    #out_video = cv2.VideoWriter( 'Manufacturing_output.mp4', cv2.VideoWriter_fourcc(*'XVID'), fps, (initial_w, initial_h), True)\n",
    "\n",
    "    counter=0\n",
    "    start_inference_time=time.time()\n",
    "\n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame=cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            counter+=1\n",
    "            alpha = 0.7\n",
    "\n",
    "\n",
    "\n",
    "            res_image, coords = pd.predict(frame)\n",
    "\n",
    "\n",
    "            num_people= queue.check_coords(coords)\n",
    "            print(f\"Total People in frame = {len(coords)}\")\n",
    "            print(f\"Number of people in queue = {num_people}\")\n",
    "\n",
    "            out_text=\"\"\n",
    "\n",
    "\n",
    "            \n",
    "            cv2.putText(res_image, f\"Total Person on screen: {len(coords)}\", (15, 35), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,153,153), 2)\n",
    "\n",
    "            overlay = res_image.copy()\n",
    "\n",
    "            for idx,q in enumerate(queue.queues):\n",
    "                    overlay = cv2.rectangle(overlay, (q[0], q[1]), (q[2], q[3]), (0, 255, 0), 5)\n",
    "                    cv2.rectangle(overlay, (q[0], q[1]), (q[0] + 240, q[1] + 80), (0,0,0), -1)\n",
    "                    cv2.putText(overlay, f\"Queue ID: {idx+1}\", (q[0]+5, q[1]+30), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0),4)  #blue,green,red \n",
    "\n",
    "                    if idx==0:\n",
    "                        v = num_people[1]\n",
    "                    elif idx ==1:\n",
    "                        v = num_people[2]\n",
    "\n",
    "                    out_text += f\"Persons: {v} \"\n",
    "                    if v >= int(max_people):\n",
    "                        msg = f\"Queue full; Please move to next Queue \"\n",
    "                        cv2.rectangle(overlay, (q[0], q[1]+100), (q[0] + 650, q[1] + 150), (0,0,0), -1)\n",
    "                        cv2.putText(overlay, msg, (q[0]+5, q[1]+135), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255),2)  #blue,green,red \n",
    "\n",
    "\n",
    "                    cv2.putText(overlay, out_text, (q[0]+5, q[1]+70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    out_text=\"\"\n",
    "\n",
    "\n",
    "            res_image = cv2.addWeighted(overlay, alpha, res_image, 1 - alpha, 0)    \n",
    "            res_image = cv2.resize(res_image, (initial_w, initial_h)) \n",
    "            out_video.write(res_image)\n",
    "\n",
    "        total_time=time.time()-start_inference_time\n",
    "        total_inference_time=round(total_time, 1)\n",
    "        fps=counter/total_inference_time\n",
    "\n",
    "        with open(os.path.join(output_path, 'stats.txt'), 'w') as f:\n",
    "            f.write(str(total_inference_time)+'\\n')\n",
    "            f.write(str(fps)+'\\n')\n",
    "            f.write(str(total_model_load_time)+'\\n')\n",
    "\n",
    "        cap.release()\n",
    "        out_video.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    except Exception as e:\n",
    "        print(\"Could not run Inference: \", e)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    parser=argparse.ArgumentParser()\n",
    "    parser.add_argument('--model', required=True)\n",
    "    parser.add_argument('--device', default='CPU')\n",
    "    parser.add_argument('--video', default=None)\n",
    "    parser.add_argument('--queue_param', default=None)\n",
    "    parser.add_argument('--output_path', default='/results')\n",
    "    parser.add_argument('--max_people', default=2)\n",
    "    parser.add_argument('--threshold', default=0.60)\n",
    "    \n",
    "    args=parser.parse_args()\n",
    "\n",
    "   \n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
